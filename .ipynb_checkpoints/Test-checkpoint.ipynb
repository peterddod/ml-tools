{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cf15825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911c18ab",
   "metadata": {},
   "source": [
    "### Simulated Annealing Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7570ffa1",
   "metadata": {},
   "source": [
    "### Baseline Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29566dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "###############\n",
    "# ELM\n",
    "###############\n",
    "class ELM():\n",
    "    def __init__(self, input_size, h_size, num_classes, device=None):\n",
    "        self._input_size = input_size\n",
    "        self._h_size = h_size\n",
    "        self._output_size = num_classes\n",
    "        self._device = device\n",
    "\n",
    "        self._alpha = nn.init.uniform_(torch.empty(self._input_size, self._h_size, device=self._device), a=-1., b=1.)\n",
    "        self._beta = nn.init.uniform_(torch.empty(self._h_size, self._output_size, device=self._device), a=-1., b=1.)\n",
    "        \n",
    "        self._alphaA = nn.init.ones_(torch.empty(self._input_size, self._h_size, device=self._device))\n",
    "        self._betaA = nn.init.ones_(torch.empty(self._h_size, self._output_size, device=self._device))\n",
    "\n",
    "#         self._bias = torch.zeros(self._h_size, device=self._device)\n",
    "#         self._biasA = torch.ones_(self._h_size, device=self._device)\n",
    "\n",
    "        self._activation = torch.relu\n",
    "\n",
    "    def predict(self, x):\n",
    "        h = self._activation(x.mm(self._alpha))\n",
    "        out = h.mm(self._beta)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def fit(self, x, t):\n",
    "        temp = x.mm(self._alpha)\n",
    "        H = self._activation(temp)\n",
    "\n",
    "        H_pinv = torch.pinverse(H)\n",
    "        self._beta = H_pinv.mm(t)\n",
    "\n",
    "\n",
    "    def evaluate(self, x, t):\n",
    "        y_pred = self.predict(x)\n",
    "        acc = torch.sum(torch.argmax(y_pred, dim=1) == torch.argmax(t, dim=1)).item() / len(t)\n",
    "        return acc\n",
    "\n",
    "#####################\n",
    "# Helper Functions\n",
    "#####################\n",
    "def to_onehot(batch_size, num_classes, y, device):\n",
    "    # One hot encoding buffer that you create out of the loop and just keep reusing\n",
    "    y_onehot = torch.FloatTensor(batch_size, num_classes).to(device)\n",
    "    #y = y.type(dtype=torch.long)\n",
    "    y = torch.unsqueeze(y, dim=1)\n",
    "    # In your for loop\n",
    "    y_onehot.zero_()\n",
    "    y_onehot.scatter_(1, y, 1)\n",
    "\n",
    "    return y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc4ec117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterdodd/miniforge3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 30 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torchvision.datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "#################\n",
    "# Parameters\n",
    "#################\n",
    "device = 'cpu'\n",
    "image_size = 28*28\n",
    "hidden_size = 200\n",
    "num_classes = 10\n",
    "\n",
    "##################\n",
    "# Datasets\n",
    "##################\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "dataset = torchvision.datasets.MNIST(root='~/AI/Datasets/mnist/data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='~/AI/Datasets/mnist/data', train=False, transform=transform, download=True)\n",
    "\n",
    "def get_all_data(dataset, num_workers=30, shuffle=False):\n",
    "    dataset_size = len(dataset)\n",
    "    data_loader = DataLoader(dataset, batch_size=dataset_size,\n",
    "                             num_workers=num_workers, shuffle=shuffle)\n",
    "\n",
    "    for i_batch, sample_batched in enumerate(data_loader):\n",
    "        images, labels = sample_batched[0].view(len(dataset), -1).to(device), sample_batched[1].to(device)\n",
    "    return images, labels\n",
    "\n",
    "train_images , train_labels = get_all_data(dataset, shuffle=True)\n",
    "train_labels = to_onehot(batch_size=len(dataset), num_classes=num_classes, y=train_labels, device=device)\n",
    "\n",
    "test_images , test_labels = get_all_data(dataset, shuffle=False)\n",
    "test_labels = to_onehot(batch_size=len(dataset), num_classes=num_classes, y=test_labels, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b04ee357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9832833333333333\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "# Model\n",
    "#################\n",
    "elm = ELM(input_size=image_size, h_size=5000, num_classes=num_classes, device=device)\n",
    "elm.fit(train_images, train_labels)\n",
    "accuracy = elm.evaluate(test_images, test_labels)\n",
    "\n",
    "print('Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b37bb0",
   "metadata": {},
   "source": [
    "### Annealing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "80aa9dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Annealer():\n",
    "    def __init__(self, input_size, h_size, num_classes, lr=1, device=None):\n",
    "        self._input_size = input_size\n",
    "        self._h_size = h_size\n",
    "        self._output_size = num_classes\n",
    "        self._device = device\n",
    "        self._lr = lr\n",
    "\n",
    "        self._alpha = nn.init.uniform_(torch.empty(self._input_size, self._h_size, device=self._device), a=-1., b=1.)\n",
    "        self._beta = nn.init.uniform_(torch.empty(self._h_size, self._output_size, device=self._device), a=-1., b=1.)\n",
    "        \n",
    "        self._alphaA = nn.init.ones_(torch.empty(self._input_size, self._h_size, device=self._device))\n",
    "        self._betaA = nn.init.ones_(torch.empty(self._h_size, self._output_size, device=self._device))\n",
    "\n",
    "        self._activation = torch.relu\n",
    "        self._loss = nn.L1Loss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = torch.unsqueeze(x,0)\n",
    "        h = self._activation(x.mm(self._alpha))\n",
    "        out = h.mm(self._beta)\n",
    "\n",
    "        return out\n",
    "    \n",
    "    # One sample\n",
    "    def step(self, X, y):\n",
    "        # get loss for sample prediction\n",
    "        pred = self.predict(X)\n",
    "#         print(pred)\n",
    "        loss = self._loss(pred, y)\n",
    "#         print(loss)\n",
    "        \n",
    "        # create boolean matrix for all active weights\n",
    "        feature_map = self._activation(torch.unsqueeze(X,0).mm(self._alpha))\n",
    "        _alphaA = self._alphaA*feature_map\n",
    "        _alphaA[_alphaA!=0] = 1\n",
    "        \n",
    "        feature_map = feature_map.mm(self._beta)\n",
    "        _betaA = self._betaA*feature_map\n",
    "        _betaA[_betaA!=0] = 1\n",
    "        \n",
    "        # increase all weights in path and decrease all weights outside of path by ratio of loss\n",
    "        self._alpha = self._alpha + _alphaA * loss * self._lr - torch.mean(self._alpha)\n",
    "        self._beta = self._beta + _betaA * loss * self._lr - torch.mean(self._beta)\n",
    "        \n",
    "        _alphaA[_alphaA==0] = 2\n",
    "        _betaA[_betaA==0] = 2\n",
    "        _alphaA[_alphaA==1] = 0\n",
    "        _betaA[_betaA==1] = 0\n",
    "        _alphaA = _alphaA/2\n",
    "        _betaA = _betaA/2\n",
    "        \n",
    "        self._alpha = self._alpha - _alphaA * loss * self._lr - torch.mean(self._alpha)\n",
    "        self._beta = self._beta - _betaA * loss * self._lr - torch.mean(self._beta)\n",
    "        \n",
    "\n",
    "    def fit(self, x, t):\n",
    "        for i, sample in enumerate(x):\n",
    "            if i==100:\n",
    "                return\n",
    "            self.step(sample, t[i])\n",
    "            \n",
    "            \n",
    "    def predict2(self, x):\n",
    "#         x = torch.unsqueeze(x,0)\n",
    "        h = self._activation(x.mm(self._alpha))\n",
    "        out = h.mm(self._beta)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "    def evaluate(self, x, t):\n",
    "        y_pred = self.predict2(x)\n",
    "        acc = torch.sum(torch.argmax(y_pred, dim=1) == torch.argmax(t, dim=1)).item() / len(t)\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ebd4d73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.18281666666666666\n"
     ]
    }
   ],
   "source": [
    "#################\n",
    "# Model\n",
    "#################\n",
    "a = Annealer(input_size=image_size, h_size=hidden_size, num_classes=num_classes, device=device)\n",
    "a.fit(train_images, train_labels)\n",
    "accuracy = a.evaluate(test_images, test_labels)\n",
    "\n",
    "print('Accuracy: {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6269cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
